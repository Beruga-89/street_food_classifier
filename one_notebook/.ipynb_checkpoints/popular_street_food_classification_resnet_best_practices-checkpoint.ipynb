{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Best Practice: Logging einrichten\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    logger.info(f\"Seed gesetzt auf {seed}\")\n",
    "\n",
    "seed_everything()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Best Practice: Zentrale Konfiguration\n",
    "class Config:\n",
    "    DATA_DIR = '/mnt/data/data/raw'\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_CLASSES = 20\n",
    "    NUM_EPOCHS = 30\n",
    "    LEARNING_RATE = 1e-3\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    LR_STEP_SIZE = 7\n",
    "    LR_GAMMA = 0.1\n",
    "    EARLY_STOPPING_PATIENCE = 5\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "cfg = Config()\n",
    "logger.info(f\"Konfiguration geladen: {cfg.__dict__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30185c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "dataset = datasets.ImageFolder(cfg.DATA_DIR, transform=transform_train)\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "val_set.dataset.transform = transform_val\n",
    "train_loader = DataLoader(train_set, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "logger.info(\"DataLoader erstellt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=cfg.EARLY_STOPPING_PATIENCE):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None or score > self.best_score:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, cfg.NUM_CLASSES)\n",
    "model.to(cfg.DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=cfg.LR_STEP_SIZE, gamma=cfg.LR_GAMMA)\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(cfg.DEVICE), labels.to(cfg.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(cfg.DEVICE), labels.to(cfg.DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    scheduler.step()\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    logger.info(f\"Epoch {epoch+1}: Train Loss={train_loss}, Val Loss={val_loss}\")\n",
    "\n",
    "    if early_stopping(val_loss, model).early_stop:\n",
    "        logger.warning(\"Fr√ºhes Stoppen aktiviert.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(cfg.DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "logger.info(f\"Validation Accuracy={acc}, F1 Score={f1}\")\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(f\"Validation F1-Score: {f1:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7417631,
     "sourceId": 11810440,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
